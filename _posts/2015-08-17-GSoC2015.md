---
layout: post
category : R Programming
tags : [GSoC, R, mlr, SVM, machine learning]
---
{% include JB/setup %}

Today is the "Suggested pencils down date" for the [Google Summer of Code 2015](https://www.google-melange.com/gsoc/homepage/google/gsoc2015). I participated in it this year, and I want to describe what I've done in this post. Basically, I worked for an R package `mlr`, my two mentors are [Bernd](https://github.com/berndbischl) and [Aydin](https://github.com/aydindemircioglu), [Lars](https://github.com/larskotthoff) is also helping a lot. The project is about several ensemble SVM learners, and some general ensemble learning algorithms.

## What is GSoC

Officially, Google Summer of Code is "a global program that offers students stipends to write code for open source projects. We have worked with the open source community to identify and fund exciting projects for the upcoming summer." This means 

- This project is helping open source projects.
- Students participating will be paid. Specifically this year's payment is 5500 USD.

Moreover,

- Each student can participate in one project
- Each project will have at least one mentor guiding the student's work. A mentor is usually an expert in this open source community.
- There are mid-term evaluation and final evaluation for both the student and mentor(s).

## Before the coding stage

### How to apply

I am especially interested in the [GNU R project](https://www.r-project.org/), which is an open-sourced language for statistical computing. In this community, experienced people have organized a [github wiki page](https://github.com/rstats-gsoc/gsoc2015/wiki/table-of-proposed-coding-projects) listing all possible projects from potential mentors. I followed these steps:

1. Check all the listed projects, pick out all I am interested in.
2. Contact the mentors for those projects, introduce myself briefly focusing on both my experiences in R and my understanding of this project.
3. Discuss with the mentors of the most possible project(s) about the proposal(s).
4. Write the proposal. Discuss the details with your mentors.
5. Wait for the decision to be made.

Things might be a bit different in other communities, but the most important things are communication with the mentors and the proposal. 

In my case, my mentors are very supportive and offered my some useful suggestions. They also asked me to add a basic learner to demonstrate the ability to write basic R program.

### How to write the proposal

There are tons of tutorials/notes/articles online on how to write the proposal for a GSoC project. Fortunately for me, my mentors have already written their expectation clearly. Based on their writing, my final proposal includes

- The description of the ensemble SVM algorithms.
- Proposed additional algorithms about ensemble learning.
- My experience in R and machine learning.
- A brief schedule for the proposed projects.

I've seen some proposal with very precise timetable (e.g. "implement xxx class on July 1st"), maybe this is just not so easy to follow for three months.

## My GSoC 2015 Project

###  The `SwarmSVM` Package

I participated in one of the projects proposed by the `mlr` organization. The project is mainly about the following three ensemble SVM learners:

- [Clustered Support Vector Machines](http://jmlr.org/proceedings/papers/v31/gu13b.html). Basic idea:
  - Training
    - Cluster the data.
    - Transform the data according to the Eq. (4) - Eq. (7) in the original paper.
    - Solve the new problem with Liblinear.
  - Prediction
    - Transform the test data according to the Eq. (4) - Eq. (7).
    - Predict with the trained model.
- [Divide-and-Conquer SVM](http://arxiv.org/abs/1311.0914). Basic idea:
  - Training
    - Sample points from the support vectors(or the whole data set on the bottom level) to run clustering algorithm.
    - For each cluster, utilize the corresponding weights from the sub level to initialize the coordinate descent algorithm.
    - Refine weights by solving SVM on all the support vectors.
    - Solve SVM on the whole data based on the refined weights.
  - Prediction
    - Finish the entire training on all levels and predict as the usual svm.
    - Early prediction based on the l-th level solution by 
      1. Assign the test data to clusters.
      2. Predict by the sub-svm.
- [Mixture of SVM Experts](http://dl.acm.org/citation.cfm?id=638957). Basic idea:
  - Training
    - Randomly divide the data set into subsets.
    - Train one svm on each subset.
    - Train a "gater" function (a neural network) on the result of these svms.
    - Reassign the data example according to the weight from the gater function.
    - Loop step 2-4 until the stopping criterion is met.
  - Prediction
    - Predict with all the svms on the full test set.
    - Put the result through the "gater" to get the final result.

These three algorithms have something in common:

1. Solve SVM on a subset of the data.
2. Combine the result from different SVM models thus lift the precision on the entire dataset.

The main reason for these attempts is that SVM training is a quadratic algorithm. Solving SVM algorithms on subsets seperately can speed up the process drastically. 

I have implemented the three algorithms in the [`SwarmSVM`](https://github.com/hetong007/SwarmSVM) package, and it is [on CRAN](https://cran.rstudio.com/web/packages/SwarmSVM/index.html) now. Besides, I have also ported them into the `mlr` package.

One of the challenges in this implementation lies in the second algorithm. The vanilla `LibSVM` doesn't accept the initialization of the weight. The author of the paper offers a MATLAB implementation with modified `LibSVM` code. I decided to merge this code and `e1071::svm` together. However because of my lack of experience in `LibSVM`, I kept having either totally wrong result or "segmentation fault" in my implementation. Debugging R's C interface is not easy for me. After I used `printf` to watch almost every step, I found out that one of the reasons is the `alpha` (which is the weight) is always positive. Debugging cost me about one week.

### The new learners and algorithms in `mlr` package

Right after I have `SwarmSVM` on CRAN, I added corresponding learners in `mlr`, so that the first goal in my proposal is achieved. Next I picked some algorithms in [this issue](https://github.com/mlr-org/mlr/issues/257) and implemented them in `mlr`.

Next I focused on more general ensemble algorithms: 

- [Getting the Most Out of Ensemble Selection](http://ieeexplore.ieee.org/xpl/login.jsp?reload=true&tp=&arnumber=4053111). Basic idea:
  - Train base learners, get their prediction value from cross validation.
  - Set the pool as empty.
  - Add a learner which maximize the overall performance to the pool.
  - Repeat the last step until there's no improvement.
- [Model compression](http://dl.acm.org/citation.cfm?id=1150464). Basic idea:
  - Train the above algorithm to get a pool of base learners on a small set of data.
  - Generate pseudo data and label it with the pool.
  - Train a neural network model to mimic the behaviour of this pool, thus compress the size of the model and shorten the time to make prediction.
- [Feature-subspace aggregating: ensembles for stable and unstable learners](http://link.springer.com/article/10.1007%2Fs10994-010-5224-5). This is proposed by my mentor Aydin. Basic idea:
  - Train a decision-tree-like structure to split the data.
  - Train a base model on each leaf with enough data points.
  - Repeat the above steps to generate a forest.

They are now also in the `mlr` package's `makeStackedLearner` and `makeFeatingEnsemble` respectively.
  











